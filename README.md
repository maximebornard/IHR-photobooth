# TODO
- finir le readme
- parler de l'idÃ©e de faire une suitÃ© d'image puis que le SAV forme une histoire style bd de ces images (avec bulles de texte)
- estimation du temps que Ã§a doit prendre
- explication des choix (IA, programmes)

#  Photo Booth IA - Mode Histoire (Mini BD en 3 cases)

PhotoBooth interactif contrÃ´lÃ© **uniquement par gestes** qui capture **3 photos successives**, applique une transformation IA cohÃ©rente pour obtenir un rendu â€œbande dessinÃ©eâ€, puis gÃ©nÃ¨re une **planche BD finale** avec **bulles de texte**.  
Le but est de transformer une sÃ©ance photobooth classique en une **mini-histoire en 3 scÃ¨nes** (dÃ©but â†’ action â†’ fin), rendue comme une vraie BD.  

## Objectifs du projet

- CrÃ©er une **expÃ©rience narrative** simple, fun, et rÃ©pÃ©table.
- Proposer un rendu final â€œcollectorâ€ (planche BD) plutÃ´t quâ€™une image unique.
- Assurer la cohÃ©rence stylistique des 3 panels.
- Placer des bulles de texte **sans masquer les personnes**.

---

## FonctionnalitÃ©s principales

### 1) Interaction 100% gestuelle (sans overlay)
Le systÃ¨me nâ€™utilise **aucun overlay** (pas de cadre, pas de zones, pas dâ€™aide visuelle).
Lâ€™interface est minimale : affichage plein Ã©cran du flux camÃ©ra, puis des captures, puis du rÃ©sultat final.

Gestes utilisÃ©s (maintien ~2 secondes) :
- **Signe V** : dÃ©clencher la capture de la photo courante
- **Pouce vers le haut** : valider la photo et passer Ã  la suivante
- **Pouce vers le bas** : rejeter la photo et la reprendre

### 2) SÃ©quence â€œHistoireâ€ en 3 photos
Le photobooth capture et valide 3 photos successives :
- Photo 1 â†’ Panel 1 (dÃ©but)
- Photo 2 â†’ Panel 2 (action)
- Photo 3 â†’ Panel 3 (fin)

Lâ€™utilisateur peut refaire une photo tant quâ€™elle nâ€™est pas validÃ©e.

### 3) GÃ©nÃ©ration IA cohÃ©rente (3 panels)
Une fois les 3 photos validÃ©es, lâ€™IA applique un style BD **cohÃ©rent entre les 3 images** :
- mÃªmes paramÃ¨tres de gÃ©nÃ©ration
- cohÃ©rence stylistique (palette, traits, ambiance)
- cohÃ©rence globale (mÃªme â€œuniversâ€ sur les 3 panels)

### 4) Bulles de texte (histoires fixes) + placement adaptatif
La planche finale contient des **bulles de texte** pour renforcer lâ€™effet BD.

- Le texte provient de **4 Ã  5 histoires fixes** (templates) stockÃ©es dans un fichier de configuration.
- Le **placement des bulles sâ€™adapte automatiquement** Ã  la position des personnes sur chaque photo :
  - on dÃ©tecte les personnes (MediaPipe Pose, optionnel Face)
  - on Ã©vite de recouvrir visages et corps
  - on choisit une zone â€œlibreâ€ parmi des positions candidates (coins / centres)

### 5) Composition automatique de la planche BD
Le systÃ¨me assemble :
- les 3 panels stylisÃ©s
- les bulles
- un **titre** (liÃ© Ã  lâ€™histoire choisie)
dans une seule image finale prÃªte Ã  afficher et Ã  imprimer/exporter.

---

## Parcours utilisateur (expÃ©rience)

1. **Ã‰cran camÃ©ra** (plein Ã©cran)
2. **Signe V** (2s) â†’ Capture Photo 1
3. **Ã‰cran preview Photo 1**
   - **Pouce vers le haut** (2s) â†’ valider et passer Ã  Photo 2
   - **Pouce vers le bas** (2s) â†’ refaire Photo 1
4. Idem pour Photo 2
5. Idem pour Photo 3
6. **Traitement IA** (gÃ©nÃ©ration des 3 panels)
7. Ajout des **bulles adaptatives**
8. Assemblage et affichage de la **planche BD finale**
9. **Pouce vers le haut** (2s) â†’ impression puis nouvelle session  
   **Pouce vers le bas** (2s) â†’ recommencer la sÃ©quence complÃ¨te

---

## Fichiers gÃ©nÃ©rÃ©s (sorties)

Le photobooth produit au minimum :

- `outputs/session_YYYYMMDD_HHMMSS/`
  - `inputs/`
    - `input_1.png`
    - `input_2.png`
    - `input_3.png`
  - `ai/`
    - `panel_1.png`
    - `panel_2.png`
    - `panel_3.png`
  - `bubbles/`
    - `panel_1_bubbled.png`
    - `panel_2_bubbled.png`
    - `panel_3_bubbled.png`
  - `final/`
    - `comic_final.png`
    - *(optionnel)* `comic_final.pdf`
  - `metadata.json` (histoire choisie, seed, paramÃ¨tres, timestamps)

---


# Architecture complÃ¨te du systÃ¨me

Cette section dÃ©crit **lâ€™architecture complÃ¨te** du PhotoBooth IA â€œMode Histoireâ€ (3 cases BD).

---

## Couches du systÃ¨me

### Couche matÃ©rielle
| Composant | Recommandation |
|---|---|
| **GPU** | NVIDIA CUDA (RTX 2060+ recommandÃ© pour SDXL) |
| **Webcam** | 720p minimum (1080p recommandÃ©), 30 FPS |
| **CPU** | 6 cÅ“urs minimum (dÃ©tection gestes + I/O) |
| **RAM** | 16 GB min, 32 GB recommandÃ© |
| **Ã‰cran** | 1920Ã—1080 min |
| **Imprimante** | compatible CUPS / pilote systÃ¨me |

### SystÃ¨me dâ€™exploitation
- Linux (Ubuntu/Debian recommandÃ©) ou Windows
- Drivers webcam (V4L2 sous Linux)
- Drivers GPU NVIDIA + CUDA
- CUPS pour lâ€™impression sous Linux

### Environnement logiciel
- Python 3.10 (recommandÃ© pour compatibilitÃ© stable cÃ´tÃ© SD WebUI)
- Un environnement virtuel dÃ©diÃ© (venv/conda)
- Stable Diffusion WebUI (Automatic1111) lancÃ© en **process sÃ©parÃ©**

---

## Vue dâ€™ensemble (diagramme)

```text
================================================================================
                          PHOTOBOOTH IA â€” MODE HISTOIRE
================================================================================

COUCHE MATERIELLE
-----------------
    Webcam USB                 GPU NVIDIA CUDA                       Imprimante
  1280x720@30fps                SDXL VRAM 9-12GB                      A6/A5/A4
        |                              |                                |
        +------------------------------+--------------------------------+
                                       |
SYSTEME D'EXPLOITATION
----------------------
Linux/Windows
- Drivers webcam
- Drivers NVIDIA
- CUPS

ENV PYTHON 3.10 (venv)
----------------------
OpenCV + MediaPipe + NumPy + Requests + Pillow
            |
            v
================================================================================
                          APPLICATION PRINCIPALE (photobooth_story.py)
================================================================================
MODULE 1: CAPTURE CAMERA
    OpenCV VideoCapture() -> frames -> affichage plein Ã©cran

MODULE 2: DETECTION GESTES
    MediaPipe Hands -> classification geste (V / ThumbUp / ThumbDown)
    + logique "maintien 2 secondes"

MODULE 3: MACHINE A ETATS (3 PHOTOS)
    IDLE -> CAPTURE_1 -> PREVIEW_1 -> CAPTURE_2 -> PREVIEW_2 -> CAPTURE_3 -> PREVIEW_3
    puis PROCESSING -> DISPLAY_RESULT

MODULE 4: GENERATION IA (SDXL img2img)
    HTTP POST /sdapi/v1/img2img (Automatic1111)
    3 requÃªtes (1 par panel) avec paramÃ¨tres cohÃ©rents (seed, prompt, CN pose)

MODULE 5: DETECTION PERSONNES (pour bulles)
    MediaPipe Pose (et option Face) sur panel_X.png
    -> zones "Ã  Ã©viter" (bounding boxes)

MODULE 6: RENDU BULLES
    Pillow : dessine bulles + texte (stories.json) placement adaptatif

MODULE 7: COMPOSITION PLANCHE BD
    Pillow : assemble 3 panels bubbled -> comic_final.png (+ pdf option)

================================================================================
                          STABLE DIFFUSION WEBUI (Automatic1111)
================================================================================
Process sÃ©parÃ©:
- Port local 127.0.0.1:7860
- API REST activÃ©e
- SDXL + ControlNet OpenPose
```

---

## Machine Ã  Ã©tats (interaction gestuelle)

Lâ€™application repose sur une machine Ã  Ã©tats claire, indispensable pour :  
- guider la capture des 3 photos  
- permettre â€œvaliderâ€ ou â€œrefaireâ€  
- dÃ©clencher la gÃ©nÃ©ration IA uniquement quand tout est validÃ©  
- simplifier le debug et les logs  

Ã‰tats:  
```text
[IDLE]
  |
  | (V âœŒï¸ maintenu 2s)
  v
[CAPTURE_1] -> [PREVIEW_1]
                 |--(ğŸ‘ 2s)--> [CAPTURE_2] -> [PREVIEW_2]
                 |--(ğŸ‘ 2s)--> [CAPTURE_1]

[PREVIEW_2]
  |--(ğŸ‘ 2s)--> [CAPTURE_3] -> [PREVIEW_3]
  |--(ğŸ‘ 2s)--> [CAPTURE_2]

[PREVIEW_3]
  |--(ğŸ‘ 2s)--> [PROCESSING] -> [DISPLAY_RESULT]
  |--(ğŸ‘ 2s)--> [CAPTURE_3]

[DISPLAY_RESULT]
  |--(ğŸ‘ 2s)--> retour [IDLE] (nouvelle session)
  |--(ğŸ‘ 2s)--> reset complet -> [CAPTURE_1]

```
---

Principes dâ€™implÃ©mentation

Boucle principale Ã  ~30 FPS (dÃ©pend webcam)

Ã€ chaque frame :

lire frame camÃ©ra

dÃ©tecter geste

mettre Ã  jour un timer de â€œmaintienâ€

valider geste si tenu â‰¥ 2s

appliquer transition dâ€™Ã©tat

Les Ã©tats CAPTURE_X ne durent quâ€™une frame :

capture instantanÃ©e

Ã©criture sur disque

passage immÃ©diat Ã  PREVIEW_X

âœ‹ DÃ©tection de gestes (sans overlay)
DÃ©pendances

mediapipe (Hands)

opencv-python (capture camÃ©ra)

numpy

Gestes attendus

âœŒï¸ Victory (index + majeur levÃ©s)

ğŸ‘ Thumb_Up

ğŸ‘ Thumb_Down

Validation par maintien (~2 secondes)

La dÃ©tection brute varie frame-to-frame. On impose donc une rÃ¨gle :

Un geste est â€œvalidÃ©â€ si :

il est dÃ©tectÃ© consÃ©cutivement pendant HOLD_TIME_SEC (ex: 2.0s)

avec une tolÃ©rance dâ€™erreur faible (ex: 2 frames max manquÃ©es)

Pseudo-logique :

si geste courant == geste prÃ©cÃ©dent : incrÃ©menter compteur

sinon : reset compteur

valider quand compteur >= HOLD_TIME_SEC * FPS_ESTIME

ParamÃ¨tres recommandÃ©s :

HOLD_TIME_SEC = 2.0

FPS_ESTIME = 30

MAX_MISSED_FRAMES = 2

ğŸ“¸ Capture & affichage
Capture

OpenCV VideoCapture(0)

rÃ©solution recommandÃ©e : 1280Ã—720

format BGR (OpenCV) converti en RGB uniquement si nÃ©cessaire (Pillow / MediaPipe)

Affichage minimaliste

fenÃªtre plein Ã©cran â€œCameraâ€ pendant IDLE / capture

fenÃªtre plein Ã©cran â€œPreviewâ€ pendant PREVIEW_X

fenÃªtre plein Ã©cran â€œResultâ€ pendant DISPLAY_RESULT

âš ï¸ Aucun overlay (pas de barres de progression ni dâ€™icÃ´nes).
Le seul â€œfeedbackâ€ est le changement de mode dâ€™affichage (camÃ©ra vs preview vs rÃ©sultat).

ğŸ§  Pipeline IA (vue globale)

Le module IA doit transformer chaque input_X.png en panel_X.png avec un style cohÃ©rent.

Principe

3 requÃªtes img2img (une par panel)

paramÃ¨tres identiques (prompt / negative prompt / sampler / steps / cfg)

seed gÃ©rÃ©e pour cohÃ©rence (voir Ã©tape 3)

ControlNet OpenPose pour conserver posture/structure

DÃ©couplage recommandÃ©

Lâ€™application photobooth ne charge pas SDXL

Elle appelle lâ€™API dâ€™Automatic1111 via HTTP :

plus stable

redÃ©marrable

logs sÃ©parÃ©s

ğŸ’¬ Placement adaptatif des bulles (vue architecture)

AprÃ¨s gÃ©nÃ©ration IA des panels, on ajoute des bulles en fonction des personnes prÃ©sentes.

EntrÃ©es

panel_X.png (image IA)

histoire choisie : stories.json (texte fixe)

style bulles : bubble_style.yaml

Ã‰tapes

DÃ©tecter la/les personnes sur panel_X.png :

MediaPipe Pose (option Face)

Convertir landmarks -> bounding boxes â€œzones Ã  Ã©viterâ€

GÃ©nÃ©rer des rectangles de bulles (selon texte + police)

Tester plusieurs positions candidates

Choisir la meilleure (score minimum)

Dessiner bulle + contour + queue + texte via Pillow

Export : panel_X_bubbled.png

ğŸ§· Composition de la planche BD

Le module â€œComposerâ€ assemble les 3 panels â€œbubbledâ€ dans une planche finale.

EntrÃ©es

panel_1_bubbled.png

panel_2_bubbled.png

panel_3_bubbled.png

titre (depuis lâ€™histoire choisie)

Sorties

comic_final.png

optionnel : comic_final.pdf

Layout recommandÃ© (simple)

3 panels alignÃ©s horizontalement (ou vertical selon imprimante)

marges externes + gouttiÃ¨re entre cases

titre en haut

Tous les paramÃ¨tres (taille, marges) doivent Ãªtre configurables.





## Logs & traÃ§abilitÃ© (recommandÃ©)

Chaque session doit Ã©crire un metadata.json contenant :

timestamp session

histoire choisie (id + titre)

chemins des images input/panel/final

seed utilisÃ©e

paramÃ¨tres SDXL (steps, cfg, denoise, sampler, model)

paramÃ¨tres bulles (font, size, positions retenues)

Câ€™est indispensable pour :

reproduire un bug

comparer des rÃ©glages IA

auditer la cohÃ©rence des sorties

ğŸ”Œ Process sÃ©parÃ©s (recommandation forte)

Le projet tourne idÃ©alement avec 2 terminaux/process :

Terminal 1 â€” Stable Diffusion WebUI (Automatic1111)

lance le serveur API sur 127.0.0.1:7860

charge SDXL + ControlNet

Terminal 2 â€” PhotoBooth Story

lance python photobooth_story.py

capture webcam + contrÃ´le gestes + appels API

Cette sÃ©paration facilite :

la stabilitÃ©

la relance en cas de crash

le debug


























# RÃ©sultat attendu
### Les photo prisent par le SAV
<img width="400" height="400" alt="image1" src="https://github.com/user-attachments/assets/3cf57bd1-2696-4c26-afb2-bfad7aee3bad" />
<img width="400" height="400" alt="image2" src="https://github.com/user-attachments/assets/bb63f815-e16f-46b4-a4d2-ef36b89ff7a3" />
<img width="183" height="275" alt="image3" src="https://github.com/user-attachments/assets/a0178629-9200-4716-adc4-1eac74ea53e0" />

### Exemple de ce que le SAV doit renvoyer
<img width="400" height="400" alt="image_final" src="https://github.com/user-attachments/assets/2e951b0a-e5db-4479-b126-0dfc58e03814" />

